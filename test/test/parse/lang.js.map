{
  "version": 3,
  "sources": ["../../src/parse/lang.ts"],
  "sourcesContent": ["import {Iter} from '@j-cake/jcake-utils/iter';\nimport {Lex, createParser, ParserBuilder} from '@j-cake/jcake-utils/parse';\n\nconst lex = Lex.createLexer({\n    open: tok => ['(', '[', '{'].find(i => tok.startsWith(i)),\n    close: tok => [')', ']', '}'].find(i => tok.startsWith(i)),\n    name: tok => tok.match(/^[a-z$_][a-z0-9$_]*/i)?.[0],\n    keyword: tok => ['fn', 'ret', 'loop', 'ptr', 'drf', 'call'].find(i => tok.startsWith(i)),\n    int: tok => tok.match(/^-?d?\\d+/)?.[0],\n    operator: tok => ['+', '-', '*', '/', '='].find(i => tok.startsWith(i)),\n    punctuator: tok => [','].find(i => tok.startsWith(i)),\n    comment: tok => tok.match(/^#.*/)?.[0],\n    whitespace: tok => tok.match(/^;?\\s+/)?.[0]\n});\n\nconst tokens = await Iter(lex([`fn main(argv, argc) {\n    ret 0 + 10\n}`]))\n    .filter(i => i.type !== 'whitespace' || i.src.includes(';'));\n\ntype T = typeof tokens extends AsyncIterable<Lex.Token<infer K>> ? K : never;\ntype K = 'Value' | 'Literal' | 'ParenthesisedExpression' | 'Expression' | 'Statement' | 'Return' | 'Fn' | 'ArgList';\n"],
  "mappings": ";AAAA,SAAQ,YAAW;AACnB,SAAQ,WAAuC;AAE/C,IAAM,MAAM,IAAI,YAAY;AAAA,EACxB,MAAM,SAAO,CAAC,KAAK,KAAK,GAAG,EAAE,KAAK,OAAK,IAAI,WAAW,CAAC,CAAC;AAAA,EACxD,OAAO,SAAO,CAAC,KAAK,KAAK,GAAG,EAAE,KAAK,OAAK,IAAI,WAAW,CAAC,CAAC;AAAA,EACzD,MAAM,SAAO,IAAI,MAAM,sBAAsB,IAAI;AAAA,EACjD,SAAS,SAAO,CAAC,MAAM,OAAO,QAAQ,OAAO,OAAO,MAAM,EAAE,KAAK,OAAK,IAAI,WAAW,CAAC,CAAC;AAAA,EACvF,KAAK,SAAO,IAAI,MAAM,UAAU,IAAI;AAAA,EACpC,UAAU,SAAO,CAAC,KAAK,KAAK,KAAK,KAAK,GAAG,EAAE,KAAK,OAAK,IAAI,WAAW,CAAC,CAAC;AAAA,EACtE,YAAY,SAAO,CAAC,GAAG,EAAE,KAAK,OAAK,IAAI,WAAW,CAAC,CAAC;AAAA,EACpD,SAAS,SAAO,IAAI,MAAM,MAAM,IAAI;AAAA,EACpC,YAAY,SAAO,IAAI,MAAM,QAAQ,IAAI;AAC7C,CAAC;AAED,IAAM,SAAS,MAAM,KAAK,IAAI,CAAC;AAAA;AAAA,EAE7B,CAAC,CAAC,EACC,OAAO,OAAK,EAAE,SAAS,gBAAgB,EAAE,IAAI,SAAS,GAAG,CAAC;",
  "names": []
}
